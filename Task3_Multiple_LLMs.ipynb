{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Connect to Multiple LLMs - Your AI Model Toolkit\n",
    "\n",
    "Learn how to connect to different language models and configure them for various use cases.\n",
    "\n",
    "## Learning Objectives\n",
    "- Connect to your first model\n",
    "- Understand the message system\n",
    "- Configure model parameters\n",
    "- Use multiple models for different purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. First Model Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the first model example\n",
    "exec(open('/workshop/task3/first_model.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Messages System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the messages demo\n",
    "exec(open('/workshop/task3/messages_demo.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model configuration demo\n",
    "exec(open('/workshop/task3/model_config.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the multiple models example\n",
    "exec(open('/workshop/task3/multiple_models.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¬ Exercise: Create Your Own Model Configuration\n",
    "\n",
    "Try different model settings and compare outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Configure models for different tasks\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Creative writing model\n",
    "creative_model = ChatOpenAI(\n",
    "    model=\"openai/gpt-4.1-mini\",\n",
    "    temperature=0.9,\n",
    "    max_tokens=100,\n",
    "    base_url=os.environ.get(\"OPENAI_API_BASE\")\n",
    ")\n",
    "\n",
    "# Analytical model\n",
    "analytical_model = ChatOpenAI(\n",
    "    model=\"openai/gpt-4.1-mini\",\n",
    "    temperature=0,\n",
    "    max_tokens=100,\n",
    "    base_url=os.environ.get(\"OPENAI_API_BASE\")\n",
    ")\n",
    "\n",
    "# Test both models with the same prompt\n",
    "prompt = \"Describe the future of artificial intelligence\"\n",
    "\n",
    "print(\"Creative Model (temp=0.9):\")\n",
    "print(creative_model.invoke(prompt).content)\n",
    "\n",
    "print(\"\\nAnalytical Model (temp=0):\")\n",
    "print(analytical_model.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Task 3 Complete!\n",
    "\n",
    "### What You've Learned\n",
    "- âœ… Basic model connection and configuration\n",
    "- âœ… Message system with different roles\n",
    "- âœ… Temperature, tokens, and streaming\n",
    "- âœ… Multiple models for different purposes\n",
    "\n",
    "### Next: Task 4 - LCEL Pipelines\n",
    "Learn to build powerful chains with LangChain Expression Language!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}